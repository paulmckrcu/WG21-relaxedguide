\documentclass[10]{article}

% standard packages

% A more pleasant font
\usepackage[T1]{fontenc} % use postscript type 1 fonts
\usepackage{textcomp} % use symbols in TS1 encoding
\usepackage{mathptmx,helvet,courier} % use nice, standard fonts for roman, sans and monospace respectively

% Improves the text layout
\usepackage{microtype}

\usepackage{lscape}
\usepackage{fancyhdr}
\usepackage{epsfig}
\usepackage{subfigure}
\usepackage{url}
\usepackage{graphics}
\usepackage{enumerate}
\usepackage{ifthen}
\usepackage{float}
\usepackage{listings}
\lstset{basicstyle=\ttfamily}
% \usepackage[strings]{underscore}
% \usepackage{underscore}
\usepackage[bookmarks=true,bookmarksnumbered=true,pdfborder={0 0 0}]{hyperref}

\lstset{
  literate={\_}{}{0\discretionary{\_}{}{\_}}%
}

\usepackage[table]{xcolor}
\usepackage{booktabs}

\DeclareUrlCommand\email{}

\pagestyle{fancy}
\rhead{}

\newfloat{listing}{tbp}{lol}
\floatname{listing}{Listing}

\begin{document}
\title{A Relaxed Guide to \co{memory_order_relaxed}}

\newcommand{\co}[1]{\lstinline[breaklines=yes,breakatwhitespace=yes]{#1}}

\author{
Hans Boehm\\\email{hboehm@google.com} \and
Paul E.~McKenney\\\email{paulmck@kernel.org} \and
The Indefatigible TBD
}
\date{August 19, 2019}
\maketitle{}

\begin{abstract}
	The out-of-thin-air (OOTA) and read-from-untaken-branch (RFUB)
	properties of the specification of \co{memory_order_relaxed}
	have resulted in considerable consternation over the years.
	Although there are no known instances of full-blown OOTA
	behavior, and no known RFUB-induced failures of production code,
	the theoretical possibility of these properties severely
	complicate automated analysis of large C and C++ code bases.
	Thus far, attempts to eliminate OOTA and RFUB properties from
	the memory model have resulted in otherwise needless added
	overheads on weakly ordered systems on the one hand or
	excessive implementation complexity on the other.
	However, \co{memory_order_relaxed} never was intended to be used
	in arbitrary code, but rather as a part of deliberate application
	of specific concurrency designs.
	This paper forms an initial catalog of patterns underlying such
	designs.
\end{abstract}

\section{OOTA and RFUB Background}
\label{sec:OOTA and RFUB Background}

@@@

Loads of citations and summaries.

Heuristics, such as single-direction data flow.

\section{Relaxed Design Patterns}
\label{sec:Relaxed Design Patterns}

Many taken from Hans's \co{memory-model-design} posting on
September 4, 2018.\footnote{
	Message-ID: \co{<CAMOCf+jchGw6DeE2NyCJA3wfFbNH-WFn59JruZPSWt9_jPW9NQ@mail.gmail.com>}.}

\subsection{Non-Racing Accesses}
\label{sec:Non-Racing Accesses}

Any non-racing access to an atomic object can be a relaxed access.
Because the access is not concurrent with a conflicting access (store
against either store or load), further ordering is unnecessary.\footnote{
	This covers case~\#8 in Hans's September 4, 2019 email.}
Important special cases of this pattern are the single-threaded
initialization and cleanup phases of an otherwise concurrent program.

In fact, such accesses can in theory be non-atomic.
In environments where atomicity is controlled by the access rather
than the object definition, such accesses are non-atomic in
practice~\cite{JadeAlglave2019WhoAfraidCompiler}.

\subsection{Single-Location Data Structures}
\label{sec:Single-Location Data Structures}

Relaxed atomic operations provide sequentially consistent access to
a single object.
This means that data structures that fit into a single object can
be accessed with relaxed atomics with no possibility of OOTA or
RFUB behavior.

Note well that a pair of single-location data structures might well
interact in a way that could raise the spectre of OOTA or RFUB.

\subsection{Shared Fences}
\label{sec:Shared Fences}

The \co{std::atomic_thread_fence()} function can be used to order
multiple sets of accesses, for example, by replacing a series of
acquire loads with relaxed loads followed by an
\co{std::atomic_thread_fence(memory_order_acquire)}~\cite[Section 4.1]{RaulSilvera2007WeakMemoryModel}
or a series of release stores with an
\co{std::atomic_thread_fence(memory_order_release)} followed by
a series of relaxed stores~\cite[Section 4.2]{RaulSilvera2007WeakMemoryModel}.

In this design pattern, OOTA and RFUB behaviors are ruled out by the semantics
of \co{std::atomic_thread_fence()}.

\subsection{Untrusted Loads}
\label{sec:Untrusted Loads}

In many cases, it is acceptable for a load from an atomic shared variable
to occasionally return random bits because the value is checked by
some later operation.
In such cases, the load can be a relaxed load.

Perhaps the most well-known later checking operation is a non-relaxed
compare-and-swap (CAS).
The \co{std::atomic_compare_exchange_*()} family of read-modify-write
CAS operations are typically used in a loop, and often require an initial
load prior to the first pass through that loop.
For non-relaxed CAS operations, this initial load can typically be a
relaxed load, with the CAS operation's ordering preventing OOTA and RFUB
behaviors.
Relaxed CAS operations need to be part of some other design pattern
(for example, the shared fences pattern called out in
Section~\ref{sec:Shared Fences}
if they are to be OOTA/RFUB-free in conjunction with an initial relaxed
load.
One common design pattern is the single-location data structure discussed in
Section~\ref{sec:Single-Location Data Structures}.

Additional examples are presented by
Sinclair et al.~\cite{Sinclair:2017:CAR:3079856.3080206}.

\subsection{Owner Field for Re-Entrant Mutex}
\label{sec:Owner Field for Re-Entrant Mutex}

\emph{Note:} There is some debate on this design pattern.

A re-entrant exclusive mutex must track its owner in order to avoid
self-deadlock when the owner re-acquires the mutex it already holds.
This owner field is updated only while the lock is held, and its value
is used only to compare for equality to the current thread's ID.
Before releasing the lock, the owner writes a special ID to the owner
field that is guaranteed not to match the ID of any thread.
Other threads can access the owner concurrently with the owner's
update, so the owner field must be an atomic in order to avoid data races.

However, the only time that the owner field can be equal to the thread ID
is when that thread carried out the last update to the owner field and
still holds the mutex:

\begin{enumerate}
\item	Each thread writes only its ID or the special ID.
\item	Because \co{memory_order_relaxed} loads are single-variable
	SC, and because each thread sets the owner field to the special
	ID before releasing the lock, a given thread cannot see its own
	ID unless it still holds the lock.
\item	Because atomic accesses forbid load tearing, each load from
	the owner field will return either the initial value
	(which is the special ID) or some value written by some
	thread holding the lock.
\item	Therefore, when a thread is not holding the lock, it is guaranteed
	not to load its own ID from the owner field.
\end{enumerate}

No other thread is allowed to write to the owner field while the lock
is held, so it is impossible to form the cycles required for OOTA or
RFUB behavior to manifest.\footnote{
	In fact, the accesses to the owner field and the mutex's acquire
	and release operations will be sequentially consistent.}
Therefore, both the reads from and the writes to the owner field
may use \co{memory_order_relaxed}.

% More generally, if an object is written only while a given mutex is
% held, all accesses to that object may be relaxed without the possibility
% of OOTA or RFUB behaviors.
% --- If all writes to all objects are protected by a given mutex, maybe.

\subsection{Allocator Caches}
\label{sec:Allocator Caches}

Allocator caches provide per-CPU or per-thread pools of free memory
in order to provide high-performance scalable memory allocation in
the common case~\cite{McKenney93}.
In practice, these pools are accessed using the moral equivalent of
relaxed accesses.
However, as before, memory allocation and pointer publication are separate
design patterns, and publication of a pointer to other threads
requires at least \co{memory_order_release} in order to ensure that
the allocation happens before the publication, even if the allocated
memory remains uninitialized.

It may be helpful to list phases of a dynamically allocated object's
lifetime:

\begin{enumerate}
\item	Allocation.
\item	Initialization, including construction.
\item	Use.
	This might include subphases, but given that any such
	subphases are defined by the user, safely transitioning between
	them is the user's responsibility.
\item	Cleanup, including destruction.
\item	Deallocation.
\end{enumerate}

Note the possibility of memory reuse means that this is a cycle rather
than a sequence.

The key point is that there must be a happens-before edge for each
phase transition.
In the case of the cleanup to deallocation to allocation to initialization
transitions, this happens-before edge is frequently supplied by
sequenced-before, courtesy of the fact that allocator caches cause
all of those transitions to occur within a single thread in the common
case.
However, some sort of happens-before edge is required for each phase
transition regardless of which thread is executing any given phase.

\subsection{One-Way Memory Allocation}
\label{sec:One-Way Memory Allocation}

``For allocating fresh memory that's never deallocated, or deallocated
with a heavy weight one-sided mechanism.''

\emph{[ How do we characterize this to avoid the infamous RFUB example?
	Here is my first cut: ]}

As in
Section~\ref{sec:Allocator Caches},
a happens-before edge is required for each transition in each
dynamically allocated object's lifetime.
This requirement rules out the infamous RFUB cycle.

\emph{[ @@@ Add citation for RFUB example. ]}

\subsection{Sequence Locking}
\label{sec:Sequence Locking}

The accesses within a sequence-locking read-side critical section can
used relaxed loads because any concurrency with the corresponding
update will result in a retry, thus discarding the loaded values.
This not only prevents the surfacing of any OOTA or RFUB cycles, but
also of any other non-SC behaviors.

\subsection{Statistical Counters}
\label{sec:Statistical Counters}

Statistical counters have concurrent updates and reads, and thus must
use atomics.
However, the concurrent reads are modeled as returning approximate results
(for example, for monitoring or debugging),
and can in fact be modeled as sequentially consistent approximate
operations.
Furthermore, data flow is almost always unidirectional, proceeding from
the updater responding to an event and flowing to the reader, precluding
the cycles required for OOTA or RFUB behavior to manifest.

Exact values are sometimes obtained from statistical counters in
stop-the-world situations, such as checking for consistent results
at the end of a stress test or benchmarking run.
Alternatively, counter updates might be carried out while read-holding
a given reader-writer lock and counter reads while write-holding
that same lock.
In all of cases, OOTA and RFUB behaviors are avoided due to the
single-threaded nature of the readout.

\subsection{Java Hashcode Access}
\label{sec:Java Hashcode Access}

\emph{[ Does this apply to C or C++? ]}

\subsection{Atomic Reference-Count Updates}
\label{sec:Atomic Reference-Count Updates}

In certain reference-count use cases, the ordering of the incremeents and
decrements is irrelevant.
One common case is where it is only legal to increment the reference
count when you already have a reference, in which case the count cannot
possibly decrease to zero in the meantime.
Because only the one-to-zero transition requires ordering, reference-count
increments can be relaxed in cases where another reference is guaranteed
to be held throughout.

\subsection{Chaotic Relaxation}
\label{sec:Chaotic Relaxation}

There are a number of iterative numerical algorithms for which unsynchronized
access does not slow convergence as much as waits for barrier synchronization.
These algorithms can use relaxed loads and stores to update the numerical
data~\cite{Andrews91textbook}.

In theory, these algorithms are subject to OOTA and RFUB behaviors, however,
in practice, current implementations avoid such behaviors.

\subsection{Garbage Collection}
\label{sec:Garbage Collection}

@@@ TBD, but believed to be subject to OOTA and RFUB. @@@

\subsection{Relaxed Consumption}
\label{sec:Relaxed Consumption}

In cases where a full-speed \co{memory_order_consume} is needed on a
weak-memory system and where the developers are willing to live within
strict coding standards~\cite{PaulEMcKenney2014rcu-dereference},
\co{memory_order_relaxed} may be used to head dependency chains.

Note well that this design pattern is outside of the current standard.

\section{Attributes of Relaxed Design Patterns}
\label{sec:Attributes of Relaxed Design Patterns}

\begin{table}
\renewcommand*{\arraystretch}{1.2}
\newcommand{\x}{\textcolor{gray!20}{\rule{7pt}{7pt}}}
\newcommand{\rothead}[1]{\begin{picture}(6,70)(0,0)\rotatebox{90}{#1}\end{picture}}
\small
\centering
\begin{tabular}{lccccccc}
	\toprule
	& \rothead{Multiple Threads}
	& \rothead{Concurrent WW}
	& \rothead{Concurrent RW}
	& \rothead{~~~~But Checked}
	& \rothead{~~~~But Discarded}
	& \rothead{~~~~Fungible Values}
	& \rothead{Unordered Cycle}
	\\
%				  MT  CWW   CRW    BC   BD   FV    UC
	\cmidrule(r){1-1} \cmidrule{2-8}
	Untrusted Loads		&  Y & \x &   Y  &  Y & \x & \x &  \x \\
	Mutex Owner Field	&  Y & \x &   Y  &  Y & \x & \x &  \x \\
	Statistical Counters	&  Y & \x &   Y  & \x & \x & \x &  \x \\
	Single-Location
	   Data Structures	&  Y &  Y &   Y  &  Y &  Y &  Y &  \x \\
	Single-Threaded
	   Processing Phases	& \x & \x &  \x  & \x & \x & \x &  \x \\
	Shared Fences		&  Y &  Y &   Y  & \x & \x & \x &  \x \\
	One-Way Memory
	   Allocation		&  Y &  Y &  \x  & \x & \x & \x &  \x \\
	Allocator Caches	& \x & \x &  \x  & \x & \x & \x &  \x \\
	Sequence Locking	&  Y & \x &   Y  & \x &  Y & \x &  \x \\
	Java Hashcode Access	&  ? &  ? &   ?  &  ? &  ? &  ? &   ? \\
	Atomic Reference-Count
	   Updates		&  Y &  Y &   Y  & \x & \x &  Y &  \x \\
	Chaotic Relaxation	&  Y &  Y &   Y  & \x & \x & \x &   Y \\
	Garbage Collection	&  ? &  ? &   ?  &  ? &  ? &  ? &   ? \\
	\bottomrule
\end{tabular}
\caption{Attributes of Relaxed Design Patterns}
\label{tab:Attributes of Relaxed Design Patterns}
\end{table}

@@@ Update @@@

Table~\ref{tab:Attributes of Relaxed Design Patterns}
shows attributes of design patterns.
The attributes are as follows:

\begin{enumerate}
\item	\emph{Multiple Threads:}  The design pattern uses multiple threads
	in and of itself.
	Note that ostensibly single-threaded patterns often interact
	with other patterns extending across multiple threads.
	For example, allocator caches operate within a single
	thread, but the resulting memory blocks and associated pointers
	will assuredly be passed to other threads using some other
	pattern such as release-acquire or release-consume.
\item	\emph{Concurrent WW:}  The design pattern involves concurrent
	relaxed writes to a given object.
\item	\emph{Concurrent RW:}  The design pattern involves concurrent
	relaxed reads and writes to a given object, but not necessarly
	concurrent relaxed writes.
\item	\emph{But Checked:}  The values from the concurrent reads are
	checked if there is the possibility of a concurrent write.
\item	\emph{But Discarded:}  The values from the concurrent reads are
	discarded if there is the possibility of a concurrent write.
\item	\emph{But Fungible:}  The values from the concurrent reads are
	fungible if there is the possibility of a concurrent write,
	that is, a fixed decision guaranteed to be made based on any
	value from a read that might have run concurrently with a write.
\item	\emph{Unordered Cycle:}  The design pattern can produce an
	unordered cycle in and of itself.
	Of course, a combination of design patterns that individually
	exclude the possibility of an unordered cycle might nevertheless
	produce an unordered cycle when used in combination.
\end{enumerate}

\section{Marking of Relaxed Design Patterns}
\label{sec:Marking of Relaxed Design Patterns}

It is currently believed that these design patterns must be explicitly marked
in order for code reviewers and automatic verifiers to recognize them
and validate their usage.
Here are some candidate marking strategies that have been discussed
within the C++ standards committee:

\begin{enumerate}
\item	Create new \co{memory_order} \co{enum} members for each new
	design pattern.
	This has the benefit of calling out the pattern in an unmistakable
	way that is visible to the compiler, but requires that each
	new design pattern be standardized.
	It also does not support the case where a given access plays a
	role in multiple overlapping design patterns.
\item	Use structured comments to mark each design pattern.
	This avoids the time delays and administrative overhead inherent
	in standardization, and could potentially allow multiple comments
	to handle a given access that plays a role in multiple overlapping
	design patterns.
\item	Use structured comments with a per-instance identifier for
	a given use of a pattern.
	The idea here is to enable tools to more easily spot
	unintended interactions between different design patterns
	being applied to a given group of objects.
	On the other hand, this raises the issue of namespace management.
\item	Define C++ \co{template} types for each design pattern.
	This is an excellent idea where it applies, as it might well
	for the statistical counters discussed in
	Section~\ref{sec:Statistical Counters}.
	However, we have reason to doubt that \co{template} types can
	be reasonably created for all possible relaxed-access design
	patterns.
\end{enumerate}

More ideation and discussion is needed on this topic.

\section{Use of Relaxed Design Patterns}
\label{sec:Use of Relaxed Design Patterns}

@@@

\section{Concluding Remarks}
\label{sec:Concluding Remarks}

@@@


\bibliographystyle{plain}
\bibliography{bib/RCU,bib/WFS,bib/hw,bib/os,bib/parallelsys,bib/patterns,bib/perfmeas,bib/refs,bib/syncrefs,bib/search,bib/swtools,bib/realtime,bib/TM,bib/standards}

\end{document}
